{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8539585,"sourceType":"datasetVersion","datasetId":5101397},{"sourceId":8540188,"sourceType":"datasetVersion","datasetId":5101861}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# IMPORT LIBRARIES\nimport requests\nfrom bs4 import BeautifulSoup\nimport json\n\n# Function to scrape a recipe from food.com\ndef scrape_recipe(url):\n    # Request the webpage\n    response = requests.get(url)\n    html_content = response.text\n\n    # Use BeautifulSoup to parse the HTML\n    soup = BeautifulSoup(html_content, 'html.parser')\n\n    # Extract the title\n    title_tag = soup.find('h1', class_='svelte-1muv3s8')\n    title = title_tag.text.strip() if title_tag else 'No title found'\n\n    # Extract the ingredients\n    ingredients_list = []\n    ingredients_ul = soup.find('ul', class_='ingredient-list')\n    if ingredients_ul:\n        for li in ingredients_ul.find_all('li', style='display: contents'):\n            quantity_span = li.find('span', class_='ingredient-quantity')\n            text_span = li.find('span', class_='ingredient-text')\n        \n            # Extract and clean up the quantity\n            quantity = ''.join(quantity_span.stripped_strings) if quantity_span else ''\n            quantity = quantity.replace('\"/\"', '/').replace(\"\\u2044\", \"/\")\n        \n            # Extract and clean up the text\n            text_parts = []\n            if text_span:\n                for part in text_span.stripped_strings:\n                    text_parts.append(part)\n                text = ' '.join(text_parts).replace('\"', '').strip()\n            else:\n                text = ''\n        \n            # Combine quantity and text\n            combined_text = f\"{quantity} {text}\"\n        \n            # Append to the ingredients list\n            ingredients_list.append(combined_text)\n    \n    # Extract the directions\n    directions_list = []\n    directions_ul = soup.find('ul', class_='direction-list')\n    if directions_ul:\n        for li in directions_ul.find_all('li', class_='direction'):\n            directions_list.append(li.text.strip())\n    \n    # Extract the cooking time\n    cooking_time_tag = soup.find('dd', class_='facts__value svelte-1dqq0pw')\n    cooking_time = cooking_time_tag.text.strip() if cooking_time_tag else 'Unknown'\n    \n    # Create recipe data\n    recipe_data = {\n        \"title\": title,\n        \"ingredients\": ingredients_list,\n        \"directions\": directions_list,\n        \"cooking_time\": cooking_time\n    }\n\n    return recipe_data\n\n# Function to read URLs from a text file\ndef read_urls(file_path):\n    with open(file_path, 'r') as file:\n        urls = [line.strip() for line in file.readlines()]\n    return urls\n\n# Main function to scrape multiple recipes and save them to a single JSON file\ndef scrape_multiple_recipes(file_path, output_file):\n    urls = read_urls(file_path)\n    all_recipes = []\n\n    for url in urls:\n        recipe = scrape_recipe(url)\n        all_recipes.append(recipe)\n\n    # Save all recipes to a JSON file\n    with open(output_file, 'w') as file:\n        json.dump(all_recipes, file, indent=4)\n\n# Path to the file containing URLs\nurls_file_path = '/kaggle/input/receipe/receipe.txt'  # Update this to the path of your text file with URLs\noutput_json_file = '/kaggle/working/recipes.json'\n\n# Scrape recipes and save to JSON\nscrape_multiple_recipes(urls_file_path, output_json_file)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-28T11:15:11.039958Z","iopub.execute_input":"2024-05-28T11:15:11.040418Z","iopub.status.idle":"2024-05-28T11:24:44.439877Z","shell.execute_reply.started":"2024-05-28T11:15:11.040383Z","shell.execute_reply":"2024-05-28T11:24:44.438384Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n\ndef process_directions(directions):\n    processed_directions = []\n    for direction in directions:\n        sentences = direction.split('. ')\n        for sentence in sentences:\n            if sentence:  # ensure it's not an empty string\n                # Remove any trailing dot and strip spaces\n                sentence = sentence.strip('.').strip()\n                processed_directions.append(sentence)\n    # Add numbering\n    numbered_directions = [f\"{i+1}. {dir}\" for i, dir in enumerate(processed_directions)]\n    return numbered_directions\n\ndef process_recipes(input_json_path, output_json_path):\n    # Load JSON data\n    with open(input_json_path, 'r') as file:\n        recipes = json.load(file)\n    \n    processed_recipes = []\n    # Process each recipe\n    for recipe in recipes:\n        processed_recipe = recipe.copy()  # Make a copy to avoid modifying the original recipe\n        processed_recipe['directions'] = process_directions(recipe['directions'])\n        processed_recipes.append(processed_recipe)\n\n    # Save the modified JSON data back to a file\n    with open(output_json_path, 'w') as file:\n        json.dump(processed_recipes, file, indent=4)\n\n# Paths to input and output JSON files\ninput_json_path = '/kaggle/input/newrecip/recipes1000.json'\noutput_json_path = '/kaggle/working/processed_recipes.json'\n\n# Process the recipes\nprocess_recipes(input_json_path, output_json_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-28T12:22:33.996326Z","iopub.execute_input":"2024-05-28T12:22:33.997738Z","iopub.status.idle":"2024-05-28T12:22:34.102929Z","shell.execute_reply.started":"2024-05-28T12:22:33.997689Z","shell.execute_reply":"2024-05-28T12:22:34.101536Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}